import streamlit as st
import pandas as pd
from datetime import date, timedelta, datetime
import json, os

st.set_page_config(page_title="ë°ì¼ë¦¬ë¡œê·¸(ì£¼ê°„+í‰ê· +ì²´í¬ë¦¬ìŠ¤íŠ¸)", layout="wide")

# =========================
# ì„¤ì •
# =========================
LOG_FILE = "weekly_log.csv"   # CSV ì €ì¥ (ê°œì¸ìš©)
DATE_FMT = "%Y-%m-%d"

ROWS = [
    "ì˜¤ëŠ˜ì˜ í• ì¼", "ì˜¤ëŠ˜ì˜ ì„±ì·¨",
    "ê¸°ë¶„", "ì—ë„ˆì§€", "ìˆ˜ë©´", "ì‹ìš•",
    "ì§‘ì¤‘ë ¥", "ê°€ì¥ ë¯¸ë£¬ì¼", "ë‘í†µ", "íŠ¹ì´ì‚¬í•­", "ê°ì •í•œì¤„ì¼ê¸°"
]
NUMERIC_1_5 = ["ê¸°ë¶„", "ì—ë„ˆì§€"]           # 1~5 í‰ê·  ëŒ€ìƒ
TASKS_COL = "ì˜¤ëŠ˜ì˜ í• ì¼"                  # ì²´í¬ë¦¬ìŠ¤íŠ¸ëŠ” JSONìœ¼ë¡œ ì €ì¥

# =========================
# ìœ í‹¸
# =========================
def load_log():
    if os.path.exists(LOG_FILE):
        df = pd.read_csv(LOG_FILE, dtype=str, encoding="utf-8-sig")
        if "date" not in df.columns:
            df["date"] = ""
        return df
    return pd.DataFrame(columns=["date"] + ROWS)

def save_log(df: pd.DataFrame):
    df = df.copy()
    if "date" in df.columns:
        df["date"] = pd.to_datetime(df["date"], errors="coerce").dt.strftime(DATE_FMT)
    df.to_csv(LOG_FILE, index=False, encoding="utf-8-sig")

def get_monday(d: date) -> date:
    return d - timedelta(days=d.weekday())  # ì›”=0

def week_dates(monday: date):
    return [monday + timedelta(days=i) for i in range(7)]

def ensure_dates_exist(df: pd.DataFrame, dates: list[date]) -> pd.DataFrame:
    existing = set(pd.to_datetime(df["date"], errors="coerce").dt.date.dropna().tolist())
    add_rows = []
    for d in dates:
        if d not in existing:
            row = {"date": d.strftime(DATE_FMT)}
            for r in ROWS:
                row[r] = "" if r != TASKS_COL else "[]"
            add_rows.append(row)
    if add_rows:
        df = pd.concat([df, pd.DataFrame(add_rows)], ignore_index=True)
    return df

def to_week_matrix(df_week: pd.DataFrame, dates: list[date]) -> pd.DataFrame:
    cols = [d.strftime(DATE_FMT) for d in dates]
    mat = pd.DataFrame(index=ROWS, columns=cols, dtype=object)
    for d in dates:
        ds = d.strftime(DATE_FMT)
        row = df_week.loc[df_week["date"] == ds]
        if not row.empty:
            row = row.iloc[0]
            for r in ROWS:
                mat.at[r, ds] = row.get(r, "")
    return mat

def apply_matrix_to_df(df: pd.DataFrame, edited_mat: pd.DataFrame):
    df = df.copy()
    for ds in edited_mat.columns:
        if not (df["date"] == ds).any():
            new_row = {"date": ds}
            for r in ROWS:
                val = edited_mat.at[r, ds] if (r in edited_mat.index) else ""
                if r == TASKS_COL and (val is None or val == ""):
                    val = "[]"
                new_row[r] = str(val) if val is not None else ""
            df = pd.concat([df, pd.DataFrame([new_row])], ignore_index=True)
        else:
            idx = df.index[df["date"] == ds][0]
            for r in ROWS:
                val = edited_mat.at[r, ds] if (r in edited_mat.index) else df.at[idx, r]
                if r == TASKS_COL and (val is None or val == ""):
                    val = "[]"
                df.at[idx, r] = str(val) if val is not None else ""
    return df

def parse_tasks(cell: str):
    """ì˜¤ëŠ˜ì˜ í• ì¼ ì…€(JSON)ì„ íŒŒì‹±í•´ ë¦¬ìŠ¤íŠ¸[{'task': str, 'done': bool}] ë°˜í™˜"""
    if not cell or pd.isna(cell):
        return []
    try:
        data = json.loads(cell)
        if isinstance(data, list):
            # ë¬¸ìì—´ ëª©ë¡ë§Œ ì €ì¥ë¼ ìˆì—ˆë‹¤ë©´ ë³€í™˜
            if data and isinstance(data[0], str):
                return [{"task": t, "done": False} for t in data]
            return data
    except Exception:
        pass
    # ì„¸ë¯¸ì½œë¡  ë¶„ë¦¬ ë“± êµ¬ë²„ì „ í˜¸í™˜
    parts = [p.strip() for p in str(cell).split(";") if p.strip()]
    return [{"task": p, "done": False} for p in parts]

def dump_tasks(tasks: list[dict]) -> str:
    # ë¹„ì–´ìˆê±°ë‚˜ taskê°€ ë¹ˆ ì¤„ì¸ ê²ƒì€ ì œê±°
    cleaned = [t for t in tasks if str(t.get("task", "")).strip() != ""]
    return json.dumps(cleaned, ensure_ascii=False)

def coerce_1_5(x):
    """ë¬¸ì/ë¹ˆì¹¸ â†’ 1~5 ìˆ«ì ë˜ëŠ” None"""
    try:
        v = int(float(str(x).strip()))
        return v if 1 <= v <= 5 else None
    except Exception:
        return None

def week_month_avg(df: pd.DataFrame, monday: date, today_dt: date):
    # ìˆ«ì ì»¬ëŸ¼ë§Œ ë½‘ì•„ì„œ 1~5ë¡œ ìºìŠ¤íŒ…
    dfx = df.copy()
    for col in NUMERIC_1_5:
        dfx[col] = dfx[col].apply(coerce_1_5)

    # ì£¼ê°„ ë²”ìœ„
    week_set = set(week_dates(monday))
    dfx["d"] = pd.to_datetime(dfx["date"], errors="coerce").dt.date
    week_df = dfx[dfx["d"].isin(week_set)]

    # ì›”ê°„ ë²”ìœ„(ì„ íƒ: ì˜¤ëŠ˜ ê¸°ì¤€ month)
    month_start = date(today_dt.year, today_dt.month, 1)
    next_month = (month_start.replace(day=28) + timedelta(days=4)).replace(day=1)
    month_end = next_month - timedelta(days=1)
    month_mask = (dfx["d"] >= month_start) & (dfx["d"] <= month_end)
    month_df = dfx[month_mask]

    def _avg(frame):
        res = {}
        for col in NUMERIC_1_5:
            series = pd.to_numeric(frame[col], errors="coerce")
            mean = series.mean() if not series.dropna().empty else None
            res[col] = round(float(mean), 2) if mean is not None else None
        return res

    return _avg(week_df), _avg(month_df), month_start, month_end

# =========================
# í™”ë©´
# =========================
st.title("ğŸ“… ë°ì¼ë¦¬ ë¡œê·¸ â€“ ì£¼ê°„ í‘œ + í‰ê·  + ì²´í¬ë¦¬ìŠ¤íŠ¸")

today = date.today()

# ---- ì‚¬ì´ë“œë°”: ì£¼ ì„ íƒ/ì´ë™ ----
with st.sidebar:
    st.header("ì£¼ ì„ íƒ")
    picked = st.date_input("ì£¼ ê¸°ì¤€ì¼(ì•„ë¬´ ë‚ ì§œë‚˜ ì„ íƒ)", today)
    monday = get_monday(picked)

    c1, c2, c3 = st.columns(3)
    with c1:
        if st.button("â—€ ì§€ë‚œì£¼"):
            monday = monday - timedelta(days=7)
    with c2:
        st.write("")
    with c3:
        if st.button("ë‹¤ìŒì£¼ â–¶"):
            monday = monday + timedelta(days=7)

    st.caption(f"í‘œ ê¸°ê°„: {monday.strftime(DATE_FMT)} ~ {(monday+timedelta(days=6)).strftime(DATE_FMT)}")

# ---- ë°ì´í„° ë¡œë“œ/ë³´ì • ----
df = load_log()
dates = week_dates(monday)
df = ensure_dates_exist(df, dates)

mask = pd.to_datetime(df["date"], errors="coerce").dt.date.isin(dates)
df_week = df[mask].copy()

# ---- ì£¼ê°„ í‘œ(í–‰=í•­ëª©, ì—´=ë‚ ì§œ) ----
mat = to_week_matrix(df_week, dates)
st.subheader("ğŸ“ ì£¼ê°„ ì…ë ¥ í‘œ (ì…€ ì§ì ‘ ìˆ˜ì •)")
st.caption("â€˜ê¸°ë¶„/ì—ë„ˆì§€â€™ëŠ” 1~5 ìˆ«ìë¡œ ì…ë ¥í•˜ì„¸ìš”. ì €ì¥í•´ì•¼ ë°˜ì˜ë©ë‹ˆë‹¤.")
edited = st.data_editor(
    mat,
    use_container_width=True,
    height=420,
    num_rows="fixed",
    key=f"week_table_{monday}"
)

c_save, c_dl = st.columns([1,1])
with c_save:
    if st.button("ğŸ’¾ ì €ì¥í•˜ê¸°", type="primary"):
        df_updated = apply_matrix_to_df(df, edited)
        save_log(df_updated)
        st.success("ì €ì¥ ì™„ë£Œ!")
        df = df_updated  # í›„ì† ì¹´ë“œ ê°±ì‹ ì„ ìœ„í•´
with c_dl:
    st.download_button(
        "â¬‡ï¸ CSV ë‹¤ìš´ë¡œë“œ",
        data=df.to_csv(index=False, encoding="utf-8-sig"),
        file_name="weekly_log_export.csv",
        mime="text/csv",
    )

# ---- í‰ê·  ì¹´ë“œ ----
wk_avg, mo_avg, mstart, mend = week_month_avg(df, monday, today)
st.subheader("ğŸ“Š ì£¼Â·ì›” í‰ê·  (1~5)")
cc1, cc2, cc3, cc4 = st.columns(4)
with cc1:
    st.metric("ì´ë²ˆì£¼ í‰ê·  ê¸°ë¶„", wk_avg.get("ê¸°ë¶„") if wk_avg.get("ê¸°ë¶„") is not None else "-")
with cc2:
    st.metric("ì´ë²ˆì£¼ í‰ê·  ì—ë„ˆì§€", wk_avg.get("ì—ë„ˆì§€") if wk_avg.get("ì—ë„ˆì§€") is not None else "-")
with cc3:
    st.metric(f"{today.strftime('%Y-%m')} í‰ê·  ê¸°ë¶„", mo_avg.get("ê¸°ë¶„") if mo_avg.get("ê¸°ë¶„") is not None else "-")
with cc4:
    st.metric(f"{today.strftime('%Y-%m')} í‰ê·  ì—ë„ˆì§€", mo_avg.get("ì—ë„ˆì§€") if mo_avg.get("ì—ë„ˆì§€") is not None else "-")
st.caption(f"ì›” ë²”ìœ„: {mstart.strftime(DATE_FMT)} ~ {mend.strftime(DATE_FMT)}")

# ---- ì˜¤ëŠ˜ ë¹ ë¥¸ ì…ë ¥: 1~5 + ì²´í¬ë¦¬ìŠ¤íŠ¸ ----
st.subheader("âš¡ ì˜¤ëŠ˜ ë¹ ë¥¸ ì…ë ¥(1~5 + ì²´í¬ë¦¬ìŠ¤íŠ¸)")
ds = today.strftime(DATE_FMT)

# ì˜¤ëŠ˜ í–‰ í™•ë³´
if (df["date"] == ds).any():
    idx_today = df.index[df["date"] == ds][0]
else:
    idx_today = len(df)
    df.loc[idx_today, "date"] = ds
    for r in ROWS:
        df.loc[idx_today, r] = "" if r != TASKS_COL else "[]"

# 1~5 ìŠ¬ë¼ì´ë”
col_a, col_b = st.columns(2)
with col_a:
    mood = st.slider("ê¸°ë¶„ (1~5)", min_value=1, max_value=5, value=coerce_1_5(df.loc[idx_today, "ê¸°ë¶„"]) or 3, step=1)
with col_b:
    energy = st.slider("ì—ë„ˆì§€ (1~5)", min_value=1, max_value=5, value=coerce_1_5(df.loc[idx_today, "ì—ë„ˆì§€"]) or 3, step=1)

# ì²´í¬ë¦¬ìŠ¤íŠ¸ í¸ì§‘
tasks = parse_tasks(df.loc[idx_today, TASKS_COL] if TASKS_COL in df.columns else "[]")
task_df = pd.DataFrame(tasks if tasks else [{"task": "", "done": False}])

task_df = st.data_editor(
    task_df,
    use_container_width=True,
    num_rows="dynamic",
    column_config={
        "task": st.column_config.TextColumn("í•  ì¼"),
        "done": st.column_config.CheckboxColumn("ì™„ë£Œ")
    },
    key="tasks_today"
)

# ë°˜ì˜ ë²„íŠ¼
if st.button("ì˜¤ëŠ˜ ê¸°ë¡ ë°˜ì˜"):
    df.loc[idx_today, "ê¸°ë¶„"] = str(mood)
    df.loc[idx_today, "ì—ë„ˆì§€"] = str(energy)
    df.loc[idx_today, TASKS_COL] = dump_tasks(task_df.to_dict(orient="records"))
    save_log(df)
    st.success("ì˜¤ëŠ˜ ê¸°ë¡ ì €ì¥ ì™„ë£Œ!")

# ---- (ì˜µì…˜) ì˜¤ëŠ˜ ì²´í¬ë¦¬ìŠ¤íŠ¸ ìš”ì•½ ----
with st.expander("â˜‘ï¸ ì˜¤ëŠ˜ í• ì¼ ìš”ì•½"):
    done_cnt = int(task_df["done"].sum()) if "done" in task_df.columns else 0
    total_cnt = int(len(task_df.index))
    st.write(f"ì™„ë£Œ {done_cnt} / ì´ {total_cnt}")
    if total_cnt:
        st.progress(done_cnt / total_cnt)
